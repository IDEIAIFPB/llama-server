LLAMA_SWAP_CONFIG_FILE=./config/llama-swap/default.yaml         # Used by llama-swap
HOST_URL=llama-server.local                                     # Used by nginx-proxy to route incoming traffic
HOST_PORT=8080
HOST_READ_TIMEOUT=36000
SERVER_PORT=8500                                                # Port that server is going to exposed through nginx
MODELS_PATH=./models
